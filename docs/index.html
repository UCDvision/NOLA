---
layout: default
title: NOLA: Compressing LoRA using Linear Combination of Random Basis
---
<br>
<div style="height:25px;">
<p style="text-align:center;"> 
  <a href="https://soroush-abbasi.github.io/">Soroush Abbasi Koohpayegani</a><sup>1,∗</sup>,
  <a href="https://www.linkedin.com/in/navaneetkl/?originalSubdomain=in">Navaneet K L</a><sup>1,∗</sup>,
  <a href="https://p-nooralinejad.github.io/">Parsa Nooralinejad</a><sup>1</sup>,
  <a href="https://skolouri.github.io">Soheil Kolouri</a><sup>2</sup></p>
  <a href="https://web.cs.ucdavis.edu/~hpirsiav/">Hamed Pirsiavash</a><sup>1</sup></p>
</div>
<br>
<div style="height:25px;">
<p style="text-align:center;"><sup>1</sup>University of California, Davis, <sup>2</sup>Vanderbilt University</p>
</div>
<div style="height:30px;">
<p style="text-align:center; font-size:12px"><sup>∗</sup> denote equal contribution</p>
</div>

<div class="menu">
  <ul style="margin: 0px;">
      <li><a href='https://arxiv.org/abs/2112.04607'>[Paper]</a></li>
      <li><a href='{{ site.baseurl }}/assets/images/CMSF_poster.pdf'>[Poster]</a></li>
      <li><a href='https://github.com/UCDvision/CMSF'>[Code]</a></li>
      <li><a href='/CMSF/bib.txt'>[Bib]</a></li>
  </ul>
</div>

<div>
<p style="text-align:center;"><img src="{{ site.baseurl }}/assets/images/cmsf_teaser.gif" width="100%" alt style></p>

  
<h5 id="abstract"><b>Abstract</b></h5>
<p>Fine-tuning Large Language Models (LLMs) and storing them for each downstream task or domain is impractical because of the massive model size (e.g., 350GB in GPT-3).
Current literature, such as LoRA, showcases the potential of low-rank modifications to the original weights of an LLM, enabling efficient adaptation and storage for task-specific models. 
These methods can reduce the number of parameters needed to fine-tune an LLM by several orders of magnitude. Yet, these methods face two primary limitations:
  (1) the parameter count is lower-bounded by the rank one decomposition, and (2) the extent of reduction is heavily influenced by both the model architecture and the chosen rank. 
We introduce NOLA, which overcomes the rank one lower bound present in LoRA. It achieves this by re-parameterizing the low-rank matrices in LoRA using linear combinations of
  randomly generated matrices (basis) and optimizing the linear mixture coefficients only. 
  This approach allows us to decouple the number of trainable parameters from both the choice of rank and the network architecture.
  We present adaptation results using GPT-2, LLaMA-2, and ViT in natural language and computer vision tasks. NOLA performs as well as LoRA models 
  with much fewer number of parameters compared to LoRA with rank one, the best compression LoRA can archive. Particularly,
  on LLaMA-2 70B, our method is almost 20 times more compact than the most compressed LoRA without degradation in accuracy.</p>

<h5 id="contributions"><b>Motivation</b></h5>
  <p> 
    We're observing the rise of fine-tuned LLMs tailored for specific tasks. For instance, OpenAI introduced GPT Store,
    allowing users to fine-tune GPT models on their datasets to develop a model with specific skills or styles.
    Storing and managing these LLMs on hardware can pose challenges, especially as the variety of LLMs continues to grow. Our goal is to reduce the model size for each LLM variation. 
    LoRA address this limitation by finetuniung only a few additional parameters for each task. We introduce NOLA to address the limitations of LoRA. 
    With NOLA, we can fine-tune models using fewer parameters compared to LoRA.

  </p>
  
  
  <h5 id="question"><b>Let’s start with an interesting question:</b></h5>
  <p style="text-align:center;"><img src="{{ site.baseurl }}/assets/images/NOLA_p1.png" width="100%" alt style></p>
  
  <p>
    We will answer to this question later. But first, let’s discuss about the limitation of LoRA. 
  </p>

  <h5 id="limitation_lora"><b>Limitation of LoRA</b></h5>
    <p> 
   The key idea of LoRA is fine-tuning only a few parameters by constraining the changes in the weight matrix to be low-rank.
  Changes in the weight matrix W can be expressed as the multiplication of two low-rank matrices, A and B with rank r. So number of optimized parameters is:  r x (m+n). 
  By using a lower rank, LoRA can significantly reduce the number of optimized parameters.
  Note that one can merge A times B with original W, therefore LoRA does not introduce any overhead during inference time. 
  </p>

<p style="text-align:center;"><img src="{{ site.baseurl }}/assets/images/lora.png" width="100%" alt style></p>
    
  <p> 
  There are two notable limitations with LoRA. First, the number of parameters depend on the model's architecture, represented by m and n, as well as the chosen rank
Second, the number of parameters is constrained by the rank one. Since rank cannot be fractional so it's impossible to decrease the number of parameters to less than m+n. 
  </p>

  <p style="text-align:center;"><img src="{{ site.baseurl }}/assets/images/nola_keyidea.png" width="100%" alt style></p>

  
  <h5 id="limitation_lora"><b>Proposed Method: NOLA</b></h5>
  
<p>
     The core idea of NOLA is to reparametrizing matrices A and B in LoRA.
  Inspired from PRANC[1] which is published in ICCV 2023, we construct A and B as linear combinations of frozen random matrices. 
These random matrices serve as the basis for A and B, and during fine-tuning, we optimize only the coefficients associated with each base matrix.

    </p>

  
<p>
  we use a scalar seed and a pseudo-random generator to generate random matrices that serve as the basis for A and B. Specifically, we generate k basis for A and l basis for B.
  Next, we multiply each random basis by its corresponding coefficient, alphas and betas, to construct A and B.

Next, we can utilize A and B for training in a manner similar to LoRA. We only optimize the coefficients and basis remain frozen during optimization.



    </p>
  

<p style="text-align:center;"><img src="{{ site.baseurl }}/assets/images/NOLA_gif.gif" width="100%" alt style></p>

  

 







<h5 id="references"><b>References</b></h5>
  <br>[1] Torchvision  models.https://pytorch.org/docs/stable/torchvision/models.html.
  <br>[2] Soroush Abbasi Koohpayegani, Ajinkya Tejankar, and Hamed Pirsiavash. Compress: Self-supervised learning by compressing representations. Advances in Neural Information Processing Systems, 33, 2020.
  <br>[3] Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Armand Joulin, Nicolas Ballas, and Michael Rabbat. Semi-supervised learning of visual features by non-parametrically predicting view assignments with support samples. ICCV, 2021.
  <br>[4] Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. Deep clustering for unsupervised learning of visual features. InProceedings of the European Conference on Computer Vision (ECCV), pages 132–149, 2018.
  <br>[5] Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and Armand Joulin. Unsupervised learning of visual features by contrasting cluster assignments. In Advances in Neural Information Processing Systems, pages 9912–9924. Curran Associates, Inc., 2020.
  <br>[6] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. arXiv preprint arXiv:2002.05709, 2020.
  <br>[7] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E Hinton. Big self-supervised models are strong semi-supervised learners. Advances in Neural Information Processing Systems, 33:22243–22255, 2020.
  <br>[8] Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He. Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297, 2020.
  <br>[9] Xinlei Chen and Kaiming He. Exploring simple siamese representation learning. arXiv preprint arXiv:2011.10566,2020.
  <br>[10] Ekin Dogus Cubuk, Barret Zoph, Jon Shlens, and Quoc Le. Randaugment: Practical automated data augmentation with a reduced search space. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 18613–18624. Curran Associates, Inc., 2020.
  <br>[11] Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Pierre Sermanet, and Andrew Zisserman. With a little help from my friends: Nearest-neighbor contrastive learning of visual representations, 2021.
  <br>[12] Spyros Gidaris, Andrei Bursuc, Gilles Puy, Nikos Komodakis, Matthieu Cord, and Patrick Perez. Obow: Online bag-of-visual-words generation for self-supervised learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 6830–6840, June 2021.
  <br>[13] Jean-Bastien  Grill,  Florian  Strub,  Florent  Altche,  Corentin Tallec,  Pierre  H  Richemond,  Elena  Buchatskaya,  Carl  Doersch,  Bernardo Avila Pires,  Zhaohan Daniel Guo,  Mohammad Gheshlaghi Azar,  et al.   Bootstrap your own latent:  A new  approach  to  self-supervised  learning. arXiv  preprintarXiv:2006.07733, 2020.
  <br>[14] Kaiming He,  Haoqi Fan,  Yuxin Wu,  Saining Xie,  and Ross Girshick.   Momentum  contrast  for  unsupervised  visual  representation learning.  InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9729–9738, 2020.
  <br>[15] Soroush Abbasi Koohpayegani, Ajinkya Tejankar, and Hamed Pirsiavash. Mean shift for self-supervised learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 10326–10335, October 2021.
  <br>[16] Ishan Misra and Laurens van der Maaten. Self-supervised learning of pretext-invariant representations. arXiv preprint arXiv:1912.01991, 2019.
  <br>[17] Hieu Pham, Zihang Dai, Qizhe Xie, and Quoc V Le. Meta pseudo labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11557–11568, 2021.
  <br>[18] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying semi-supervised learning with consistency and confidence. Advances in Neural Information Processing Systems, 33, 2020. 
  <br>[19] Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Vipin Pillai, Paolo Favaro, and Hamed Pirsiavash. ISD: Self-supervised learning by iterative similarity distillation, 2020.  
  <br>[20] Feng Wang, Huaping Liu, Di Guo, and Sun Fuchun. Unsupervised representation learning by invariance propagation. In Advances in Neural Information Processing Systems, volume 33, pages 3510–3520. Curran Associates, Inc., 2020.
  <br>[21] Guangrun Wang, Keze Wang, Guangcong Wang, Philip H. S. Torr, and Liang Lin. Solving inefficiency of self-supervised representation learning, 2021.
  <br>[22] Chen Wei, Huiyu Wang, Wei Shen, and Alan Yuille.  Co2: Consistent contrast for unsupervised visual representation learning. arXiv preprint arXiv:2010.02217, 2020.
  <br>[23] Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V Le. Unsupervised data augmentation for consistency training. NeurIPS, 2020.
  <br>[24] Asano YM., Rupprecht C., and Vedaldi A. Self-labelling via simultaneous clustering and representation learning. In International Conference on Learning Representations, 2020.

  
